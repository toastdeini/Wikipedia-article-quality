{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports, Read-in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:05:59.704192Z",
     "start_time": "2022-05-18T21:05:59.684692Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data manip.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Vizz\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.model_selection import train_test_split, cross_validate, GridSearchCV\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# NLTK\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# nltk.download('stopwords')\n",
    "sw = stopwords.words('english')\n",
    "\n",
    "# etc.\n",
    "import sys\n",
    "sys.path.append( '../src' )\n",
    "from parse_it import get_wordnet_pos, parse_doc\n",
    "from pretty_results import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is stored in two separate `.csv` files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:45:59.666747Z",
     "start_time": "2022-05-18T20:45:55.205334Z"
    }
   },
   "outputs": [],
   "source": [
    "df_good = pd.read_csv('../../data/good.csv')\n",
    "df_promo = pd.read_csv('../../data/promotional.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a look at a sample article from the `good` articles dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:46:16.505622Z",
     "start_time": "2022-05-18T20:46:16.486493Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_good.iloc[138].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing out a custom function, `parse_doc`, which takes care of several NLP preprocessing steps: lowercasing, punctuation and character stripping, lemmatizing, and removing stopwords. It returns a string of *non-unique lemmas*, but can also return a list by setting the argument `as_list = True`. If stemming is preferred to lemmatizing, this can also be done within the function: `stem = 'stem'`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:46:23.784259Z",
     "start_time": "2022-05-18T20:46:23.738963Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "parse_doc( df_good.iloc[138].text )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And, just to get the lay of the land, a look at one of the `promotional` articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:47:09.285346Z",
     "start_time": "2022-05-18T20:47:09.273281Z"
    }
   },
   "outputs": [],
   "source": [
    "df_promo.iloc[138].text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sample Size, Scope, and Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:26.962188Z",
     "start_time": "2022-05-18T20:28:26.954209Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(df_good.shape)\n",
    "print(df_promo.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:27.543911Z",
     "start_time": "2022-05-18T20:28:27.532553Z"
    }
   },
   "outputs": [],
   "source": [
    "df_good.shape[0] + df_promo.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In terms of **rows/records**,\n",
    "- The dataframe containing **\"good\"** articles has 30,279 entries.\n",
    "- The dataframe containing **\"promotional\"** articles has 23,837 entries.\n",
    "\n",
    "Combined, we have **54,116** articles for examination.\n",
    "\n",
    "Next, let's discuss features/columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:28.353905Z",
     "start_time": "2022-05-18T20:28:28.347924Z"
    }
   },
   "outputs": [],
   "source": [
    "print(df_good.columns)\n",
    "print(df_promo.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The dataframe containing **\"good\"** articles has 2 columns - `text` and `url`.\n",
    "- The dataframe containing **\"promotional\"** articles has 7 columns - in addition to `text` and `url`, there are five subtypes of \"promotional tone\":\n",
    "\n",
    "    - `advert`: The article reads like an advertisement.\n",
    "    - `coi`: The article appears to have been written by someone with a close connection to the subject.\n",
    "    - `fanpov`: The article appears to have been written from a fan's point of view, rather than a neutral point of view.\n",
    "    - `pr`: The article reads like a press release/news article.\n",
    "    - `resume`: The (biographical) article reads like a résumé, i.e. it is neither neutral nor encylopedic in nature.\n",
    "    \n",
    "    The values contained in these columns are one-hot encoded binary values. See the dataframe heads below for a tabular representation of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:29.546419Z",
     "start_time": "2022-05-18T20:28:29.504124Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_good.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:30.121535Z",
     "start_time": "2022-05-18T20:28:30.106904Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_promo.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Side Investigation: Average Length of Articles?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While reading in the data, I noticed that the `promotional` article I selected at semi-random was considerably shorter than the semi-random `good` article - I had to wonder if this observation held true at all in the rest of the dataset and decided to investigate average article length for each class.\n",
    "\n",
    "`len()` can give us a count of characters - `split()` must be used to get a word count."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:31.088548Z",
     "start_time": "2022-05-18T20:28:31.079573Z"
    }
   },
   "outputs": [],
   "source": [
    "print(len(df_good.iloc[0].text))\n",
    "print(len(df_good.iloc[0].text.split()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use string methods on the dataframes by calling `.str` - this makes calculations a lot easier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:50:00.812309Z",
     "start_time": "2022-05-18T20:50:00.773077Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_good.text.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:50:01.124457Z",
     "start_time": "2022-05-18T20:50:01.085561Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_promo.text.str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:33.142504Z",
     "start_time": "2022-05-18T20:28:33.102607Z"
    }
   },
   "outputs": [],
   "source": [
    "avg_char_good = df_good.text.str.len().mean()\n",
    "avg_char_promo = df_promo.text.str.len().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:42.683949Z",
     "start_time": "2022-05-18T20:28:33.830398Z"
    }
   },
   "outputs": [],
   "source": [
    "split_words_good = df_good.text.str.split()\n",
    "split_words_promo = df_promo.text.str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:43.482825Z",
     "start_time": "2022-05-18T20:28:43.463873Z"
    }
   },
   "outputs": [],
   "source": [
    "word_count_good = 0\n",
    "\n",
    "for article in split_words_good:\n",
    "    word_count_good += len(article)\n",
    "    \n",
    "avg_words_good = word_count_good / len(split_words_good)\n",
    "\n",
    "print(avg_words_good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:44.319396Z",
     "start_time": "2022-05-18T20:28:44.301743Z"
    }
   },
   "outputs": [],
   "source": [
    "word_count_promo = 0\n",
    "\n",
    "for article in split_words_promo:\n",
    "    word_count_promo += len(article)\n",
    "    \n",
    "avg_words_promo = word_count_promo / len(split_words_promo)\n",
    "\n",
    "print(avg_words_promo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:45.333936Z",
     "start_time": "2022-05-18T20:28:45.323928Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(f\"Average 'good' article length: {avg_char_good:.0f} characters, {avg_words_good:.0f} words\")\n",
    "print(f\"Average 'promotional' article length: {avg_char_promo:.0f} characters, {avg_words_promo:.0f} words\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:50:32.622705Z",
     "start_time": "2022-05-18T20:50:32.615647Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Visualization of average lengths\n",
    "\n",
    "# fig, ax = plt.subplots(nrows=2,\n",
    "#                        ncols=1,\n",
    "#                        figsize=(12, 12))\n",
    "\n",
    "# ax[0].bar(x=['Good', 'Promo'],\n",
    "#            height=(avg_words_good, avg_words_promo))\n",
    "\n",
    "# ax[1].bar(x=['Good', 'Promo'],\n",
    "#           height=(avg_char_good, avg_char_promo))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for Nulls / Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:48.970373Z",
     "start_time": "2022-05-18T20:28:48.938469Z"
    }
   },
   "outputs": [],
   "source": [
    "df_good.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:49.298783Z",
     "start_time": "2022-05-18T20:28:49.275818Z"
    }
   },
   "outputs": [],
   "source": [
    "df_promo.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Value Counts for Subclasses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowing there are five different subtypes of promotional article indicated within the dataset raises a further question: *how are those subtypes distributed?*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:51.036202Z",
     "start_time": "2022-05-18T20:28:51.027711Z"
    }
   },
   "outputs": [],
   "source": [
    "df_promo.select_dtypes(include='number').columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:51.523980Z",
     "start_time": "2022-05-18T20:28:51.504740Z"
    }
   },
   "outputs": [],
   "source": [
    "# class_cols = df_promo.select_dtypes(include='number').columns\n",
    "class_cols = df_promo.select_dtypes(include='number').columns.tolist()\n",
    "\n",
    "class_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:52.410115Z",
     "start_time": "2022-05-18T20:28:52.374459Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for col in class_cols:\n",
    "    print(f\"{df_promo[[col]].value_counts(normalize=True)}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:28:53.679596Z",
     "start_time": "2022-05-18T20:28:53.658685Z"
    }
   },
   "outputs": [],
   "source": [
    "df_promo.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:29:16.604085Z",
     "start_time": "2022-05-18T20:29:16.318363Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(nrows=1,\n",
    "                       ncols=5,\n",
    "                       figsize=(30,6),\n",
    "                       sharey='all')\n",
    "\n",
    "ax[0].bar(x=df_promo['advert'].value_counts(normalize=True).index,\n",
    "          height=df_promo['advert'].value_counts(normalize=True).values,\n",
    "          tick_label=['True', 'False'])\n",
    "ax[0].set_title(\"Advertisement-like\")\n",
    "\n",
    "ax[1].bar(x=df_promo['coi'].value_counts(normalize=True).index,\n",
    "          height=df_promo['coi'].value_counts(normalize=True).values,\n",
    "          tick_label=['False', 'True'])\n",
    "ax[1].set_title(\"Conflict of interest\")\n",
    "\n",
    "ax[2].bar(x=df_promo['fanpov'].value_counts(normalize=True).index,\n",
    "          height=df_promo['fanpov'].value_counts(normalize=True).values,\n",
    "          tick_label=['False', 'True'])\n",
    "ax[2].set_title(\"Written from fan's point of view\")\n",
    "\n",
    "ax[3].bar(x=df_promo['pr'].value_counts(normalize=True).index,\n",
    "          height=df_promo['pr'].value_counts(normalize=True).values,\n",
    "          tick_label=['False', 'True'])\n",
    "ax[3].set_title(\"Written like a news article/press release\")\n",
    "\n",
    "ax[4].bar(x=df_promo['resume'].value_counts(normalize=True).index,\n",
    "          height=df_promo['resume'].value_counts(normalize=True).values,\n",
    "          tick_label=['False', 'True'])\n",
    "ax[4].set_title(\"Reads like a résumé\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set-up for Simple Binary Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we drop all columns but `text`, which will be our primary feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:30:32.518500Z",
     "start_time": "2022-05-18T20:30:32.497488Z"
    }
   },
   "outputs": [],
   "source": [
    "df_good = df_good[['text']]\n",
    "df_promo = df_promo[['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before concatening the simplified dataframes, I create a new column `label` in each dataframe and give it the same value in every row. In `df_good`, each row is given the label `0` to indicate `False`, i.e. the article does ***not*** have a promotional tone. Conversely, each row in `df_promo` is given the label `1` to represent `True`, that the article ***does*** contain content that is promotional in tone.\n",
    "\n",
    "Multi-class classification is explored in a [separate notebook](Multi-label.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:30:32.992154Z",
     "start_time": "2022-05-18T20:30:32.979190Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_good['label'] = 0\n",
    "df_good.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:30:33.243554Z",
     "start_time": "2022-05-18T20:30:33.211989Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df_promo['label'] = 1\n",
    "df_promo.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we concatenate the dataframes using the pandas method `.append` - setting `ignore_index` to `True` means that the unique index values from `df_promo` are not carried over when this dataframe is appended to `df_good`; the indexing, rather, continues where `df_good`'s index leaves off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:30:34.169247Z",
     "start_time": "2022-05-18T20:30:34.151297Z"
    }
   },
   "outputs": [],
   "source": [
    "df = df_good.append(other=df_promo,\n",
    "                    ignore_index=True)\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T18:44:15.736633Z",
     "start_time": "2022-05-18T18:44:15.692277Z"
    }
   },
   "outputs": [],
   "source": [
    "# df = df.sample(frac = 1).reset_index(drop=True)\n",
    "\n",
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T18:50:04.269431Z",
     "start_time": "2022-05-18T18:50:04.262450Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# freq_out(df, 'text', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T19:52:13.158163Z",
     "start_time": "2022-05-18T18:50:09.350523Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# df['text_lem'] = df['text'].apply(parse_doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:03:15.059120Z",
     "start_time": "2022-05-18T20:02:53.739159Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv('lemmed_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading in Newly Created csv file (with lemmas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:02:12.553238Z",
     "start_time": "2022-05-18T21:02:04.765060Z"
    }
   },
   "outputs": [],
   "source": [
    "lemmed_df = pd.read_csv('../../data/lemmed_combined.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:02:12.614786Z",
     "start_time": "2022-05-18T21:02:12.601169Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "      <th>text_lem</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ryan Steven Lochte lkti LOK tee born August 3,...</td>\n",
       "      <td>0</td>\n",
       "      <td>ryan steven lochte lkti lok tee bear august am...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CAM ships were World War II era British mercha...</td>\n",
       "      <td>0</td>\n",
       "      <td>cam ship world war ii era british merchant shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The politics of Vietnam are defined by a singl...</td>\n",
       "      <td>0</td>\n",
       "      <td>politics vietnam define single party socialist...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label  \\\n",
       "0  Ryan Steven Lochte lkti LOK tee born August 3,...      0   \n",
       "1  CAM ships were World War II era British mercha...      0   \n",
       "2  The politics of Vietnam are defined by a singl...      0   \n",
       "\n",
       "                                            text_lem  \n",
       "0  ryan steven lochte lkti lok tee bear august am...  \n",
       "1  cam ship world war ii era british merchant shi...  \n",
       "2  politics vietnam define single party socialist...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmed_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:24:59.427803Z",
     "start_time": "2022-05-18T20:24:59.367003Z"
    }
   },
   "outputs": [],
   "source": [
    "additional_sw = ['january',\n",
    "                 'february',\n",
    "                 'april', # 'march' and 'may' are English verbs and\n",
    "                          #  are thus excluded\n",
    "                 'june',\n",
    "                 'july',\n",
    "                 'august',\n",
    "                 'september',\n",
    "                 'october',\n",
    "                 'november',\n",
    "                 'december']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modeling Setup/Brainstorming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:02:12.693107Z",
     "start_time": "2022-05-18T21:02:12.680438Z"
    }
   },
   "outputs": [],
   "source": [
    "X = lemmed_df['text_lem']\n",
    "y = lemmed_df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:02:12.755576Z",
     "start_time": "2022-05-18T21:02:12.741404Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        ryan steven lochte lkti lok tee bear august am...\n",
       "1        cam ship world war ii era british merchant shi...\n",
       "2        politics vietnam define single party socialist...\n",
       "3        pennsylvania route pa state highway locate mon...\n",
       "4        clubland tv british free air dance music chann...\n",
       "                               ...                        \n",
       "54111    guatemala send delegation compete summer paral...\n",
       "54112    charles augustus ollivierre july march vincent...\n",
       "54113    dhanushka jayakody bear july colombo sri lanka...\n",
       "54114    elmer harrison flick january january american ...\n",
       "54115    safdarjung tomb sandstone marble mausoleum del...\n",
       "Name: text_lem, Length: 54116, dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:02:12.832654Z",
     "start_time": "2022-05-18T21:02:12.811665Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        1\n",
       "        ..\n",
       "54111    0\n",
       "54112    0\n",
       "54113    1\n",
       "54114    0\n",
       "54115    0\n",
       "Name: label, Length: 54116, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:02:15.312355Z",
     "start_time": "2022-05-18T21:02:15.276770Z"
    }
   },
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    test_size=0.33,\n",
    "                                                    random_state=42,\n",
    "                                                    stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:02:15.559676Z",
     "start_time": "2022-05-18T21:02:15.541485Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.559533\n",
       "1    0.440467\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:02:15.949343Z",
     "start_time": "2022-05-18T21:02:15.940080Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.559494\n",
       "1    0.440506\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DummyClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:03:49.879994Z",
     "start_time": "2022-05-18T21:02:19.403334Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.560\n",
      "Test accuracy:     0.560\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.359\n",
      "Test F1 score:     0.359\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:  1.5min finished\n"
     ]
    }
   ],
   "source": [
    "dum_pipe = Pipeline(steps=[\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('dum', DummyClassifier(strategy='most_frequent'))\n",
    "])\n",
    "\n",
    "dum_cv_res = cross_validate(dum_pipe,\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            scoring=('accuracy', 'f1_macro'),\n",
    "                            cv=5,\n",
    "                            verbose=1,\n",
    "                            n_jobs=-2,\n",
    "                            return_train_score=True)\n",
    "\n",
    "pretty_cv(dum_cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from cross-validation with `DummyClassifier`:\n",
    "- Validation accuracy = 0.56 - **baseline performance**\n",
    "- Validation F1 = 0.36\n",
    "- **Execution time:** 1 m, 30 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `DecisionTreeClassifier`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T21:10:52.022954Z",
     "start_time": "2022-05-18T21:06:54.645477Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Using backend LokyBackend with 7 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 1.000\n",
      "Test accuracy:     0.873\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 1.000\n",
      "Test F1 score:     0.871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-2)]: Done   5 out of   5 | elapsed:  4.0min finished\n"
     ]
    }
   ],
   "source": [
    "dtc_pipe = Pipeline(steps=[\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('dtc', DecisionTreeClassifier())\n",
    "])\n",
    "\n",
    "dtc_cv_res = cross_validate(dtc_pipe,\n",
    "                            X_train,\n",
    "                            y_train,\n",
    "                            scoring=('accuracy', 'f1_macro'),\n",
    "                            cv=5,\n",
    "                            verbose=1,\n",
    "                            n_jobs=-2,\n",
    "                            return_train_score=True)\n",
    "\n",
    "pretty_cv(dtc_cv_res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Results from cross-validation with `DecisionTreeClassifer`:\n",
    "- Validation accuracy = 0.87\n",
    "- Validation F1 = 0.87\n",
    "- **Execution time:** 3 m, 57 s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `MultinomialNB`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `RandomForestClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `GradientBoostingClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `XGBRFClassifier`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (learn-env)",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
