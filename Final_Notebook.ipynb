{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Wikipedia Article Quality With Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/tomes.jpg)\n",
    "\n",
    "*(photo courtesy of Dmitrij Paskevic, hosted on [Unsplash](https://unsplash.com/photos/YjVa-F9P9kk))*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "> **Luke Dowker** ([GitHub](https://github.com/toastdeini) | [LinkedIn](https://www.linkedin.com/in/luke-dowker/) | [Email](mailto:lhdowker@gmail.com))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries, Packages, and Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:44:48.016798Z",
     "start_time": "2022-05-29T06:44:47.994928Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data comprehension/manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading in stored objects\n",
    "import pickle\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine learning packages\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Natural language processing\n",
    "import nltk\n",
    "\n",
    "# etc.\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.pardir)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# Custom/helper functions\n",
    "from src.parse_it import *\n",
    "from src.modeling import *\n",
    "from src.EDA import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data\n",
    "\n",
    "Full exploratory data analysis for this project can be found in [a separate notebook](prep/Exploratory_Analysis.ipynb); this final notebook contains the most notable parts of that analysis, with truncated/imported code whenever possible.\n",
    "\n",
    "Data is stored in two separate `.csv` files; one contains articles marked as \"good,\" while the other contains articles marked as \"promotional,\" with various subclasses of \"promotional.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:44:53.015608Z",
     "start_time": "2022-05-29T06:44:48.373529Z"
    }
   },
   "outputs": [],
   "source": [
    "df_good = pd.read_csv('../data/good.csv')\n",
    "df_promo = pd.read_csv('../data/promotional.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Exploration and Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:44:53.062016Z",
     "start_time": "2022-05-29T06:44:53.048802Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30279 documents in this file/dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nycticebus linglom is a fossil strepsirrhine p...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/%3F%20Nycticebus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oryzomys pliocaenicus is a fossil rodent from ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/%3F%20Oryzomys%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.hack dt hk is a series of single player actio...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/.hack%20%28video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The You Drive Me Crazy Tour was the second con...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/%28You%20Drive%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 8 4 is the second episode of the first seaso...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/0-8-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Nycticebus linglom is a fossil strepsirrhine p...   \n",
       "1  Oryzomys pliocaenicus is a fossil rodent from ...   \n",
       "2  .hack dt hk is a series of single player actio...   \n",
       "3  The You Drive Me Crazy Tour was the second con...   \n",
       "4  0 8 4 is the second episode of the first seaso...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://en.wikipedia.org/wiki/%3F%20Nycticebus...  \n",
       "1  https://en.wikipedia.org/wiki/%3F%20Oryzomys%2...  \n",
       "2  https://en.wikipedia.org/wiki/.hack%20%28video...  \n",
       "3  https://en.wikipedia.org/wiki/%28You%20Drive%2...  \n",
       "4                https://en.wikipedia.org/wiki/0-8-4  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{df_good.shape[0]} documents in this file/dataset:\") \n",
    "df_good.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:44:53.125417Z",
     "start_time": "2022-05-29T06:44:53.111447Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23837 documents in this file/dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>advert</th>\n",
       "      <th>coi</th>\n",
       "      <th>fanpov</th>\n",
       "      <th>pr</th>\n",
       "      <th>resume</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Litre no Namida 1, lit. 1 Litre of Tears als...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/1%20Litre%20no%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1DayLater was free, web based software that wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/1DayLater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1E is a privately owned IT software and servic...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/1E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1Malaysia pronounced One Malaysia in English a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/1Malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Jerusalem Biennale, as stated on the Bienn...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/1st%20Jerusalem%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  advert  coi  fanpov  pr  \\\n",
       "0  1 Litre no Namida 1, lit. 1 Litre of Tears als...       0    0       1   0   \n",
       "1  1DayLater was free, web based software that wa...       1    1       0   0   \n",
       "2  1E is a privately owned IT software and servic...       1    0       0   0   \n",
       "3  1Malaysia pronounced One Malaysia in English a...       1    0       0   0   \n",
       "4  The Jerusalem Biennale, as stated on the Bienn...       1    0       0   0   \n",
       "\n",
       "   resume                                                url  \n",
       "0       0  https://en.wikipedia.org/wiki/1%20Litre%20no%2...  \n",
       "1       0            https://en.wikipedia.org/wiki/1DayLater  \n",
       "2       0                   https://en.wikipedia.org/wiki/1E  \n",
       "3       0            https://en.wikipedia.org/wiki/1Malaysia  \n",
       "4       0  https://en.wikipedia.org/wiki/1st%20Jerusalem%...  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{df_promo.shape[0]} documents in this file/dataset:\") \n",
    "df_promo.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious about the distribution of subclasses in `df_promo` - that is, in what way can its promotional tone *best be described?* - I plotted the value counts of the categorical columns:\n",
    "\n",
    "- **Advertisement-like** / `advert` - The article reads like an advertisement for a company, a product, or an organization, or is otherwise an advertisement \"masquerading\" as a legitimate article.\n",
    "- **Conflict of interest** / `coi` - There appears to be a conflict of interest between the subject of the article and the author of the article, which \"undermines public confidence\" in Wikipedia.\n",
    "- **Fan's point of view** / `fanpov` - The article appears to have been written by a fan or admirer of the subject, rather than from a neutral point of view.\n",
    "- **News article/press release-like** / `pr` - The article reads like a news article, i.e. \"the article may not be promotional or overly-negative, but is still unencyclopedic in tone.\"\n",
    "- **Résumé-like** / `resume` - The article reads like a résumé or CV.\n",
    "\n",
    "---\n",
    "\n",
    "![img](images/promo_dist.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imbalance of promotional subclasses in the dataset, along with the overlap in semantic meaning between the subclass descriptions - *are these not all 'promotional' in some form or another?* - shaped my decision to approach this project as a **binary classification problem**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:44:53.187540Z",
     "start_time": "2022-05-29T06:44:53.172347Z"
    }
   },
   "outputs": [],
   "source": [
    "df_good = df_good[['text']]\n",
    "df_promo = df_promo[['text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:44:53.264627Z",
     "start_time": "2022-05-29T06:44:53.240666Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nycticebus linglom is a fossil strepsirrhine p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Nycticebus linglom is a fossil strepsirrhine p...      0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning 'good' articles the label 0, a 'falsy' value,\n",
    "# indicating that the article is NOT promotional\n",
    "\n",
    "df_good['label'] = 0\n",
    "df_good.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:44:53.310204Z",
     "start_time": "2022-05-29T06:44:53.296933Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Litre no Namida 1, lit. 1 Litre of Tears als...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  1 Litre no Namida 1, lit. 1 Litre of Tears als...      1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning 'promotional' articles the label 1, a 'truthy'\n",
    "# value, indicating that the article IS promotional\n",
    "\n",
    "df_promo['label'] = 1\n",
    "df_promo.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:44:53.372589Z",
     "start_time": "2022-05-29T06:44:53.361652Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\toast\\AppData\\Local\\Temp\\ipykernel_4404\\1471740015.py:4: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  df = df_good.append(df_promo,\n"
     ]
    }
   ],
   "source": [
    "# Concatenate dataframes - reset index of `df_promo`\n",
    "# for numeric consistency\n",
    "\n",
    "df = df_good.append(df_promo,\n",
    "                    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:44:53.450089Z",
     "start_time": "2022-05-29T06:44:53.420804Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle dataframe for randomness, etc.\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/median_word_count.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:45:05.097299Z",
     "start_time": "2022-05-29T06:44:53.497001Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean document length, label 0: 2629 words, 15649 characters.\n",
      "Mean document length, label 1: 768 words, 4771 characters.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(2628.5815581756333, 768.2722658052608)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare_mean_counts(df, 'text', 'label', 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is one of the most computationally expensive tasks in this whole project - it applies the custom function `parse_doc` (see the [.py file](src/parse_it.py) for further information) to the content of the `text` column for each row in the dataframe, i.e. each document in the corpus. The result is a string of **lemmas**, the approximate morphological roots of each word in the document, stored in a new column called `text_lem`. This helps standardize the text for vectorization and, eventually, modeling.\n",
    "\n",
    "Again, the following two cells are only necessary to run if you're interested in completing reproducing the project, step by step. For convenience, the output is saved as `lemmed_combined.csv`, which will probably save you at least an hour of computing time if loaded in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:46:11.695315Z",
     "start_time": "2022-05-29T06:46:11.683350Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['text_lem'] = df['text'].apply(parse_doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:46:11.925728Z",
     "start_time": "2022-05-29T06:46:11.921721Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv('lemmed_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods and Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:46:52.111808Z",
     "start_time": "2022-05-29T06:46:43.582402Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in usable dataframe\n",
    "\n",
    "df = pd.read_csv('../data/lemmed_combined.csv',\n",
    "                 index_col=0)\n",
    "\n",
    "# Reorder columns, keeping only the lemmatized text\n",
    "\n",
    "df = df[['text_lem', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:46:52.158496Z",
     "start_time": "2022-05-29T06:46:52.145075Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df['text_lem']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:46:52.450743Z",
     "start_time": "2022-05-29T06:46:52.191352Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=138,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Secondary train-test split for validation\n",
    "\n",
    "X_tr_val, X_val, y_tr_val, y_val = train_test_split(X_train, y_train,\n",
    "                                                    random_state=138,\n",
    "                                                    stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model: `DummyClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn's `DummyClassifier` was used as a baseline for measuring model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:44:11.212824Z",
     "start_time": "2022-05-29T06:44:11.199537Z"
    }
   },
   "outputs": [],
   "source": [
    "dum_pipe = Pipeline(steps=[\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('dum', DummyClassifier(strategy='most_frequent'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:50:40.134883Z",
     "start_time": "2022-05-25T21:50:17.472622Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                ('dum', DummyClassifier(strategy='most_frequent'))])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum_pipe.fit(X_tr_val, y_tr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:51:06.091372Z",
     "start_time": "2022-05-25T21:50:40.213973Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.559526938239159"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dum_pipe.score(X_tr_val, y_tr_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm Exploration\n",
    "\n",
    "To create some simple models, I train scikit-learn's `MultinomialNB` algorithm (default hyperparameters) on two vectorized instances of the corpus: One using a `CountVectorizer`, a simple bag-of-words approach, and the other using `TfidfVectorizer`, a term importance approach. Accuracy and $F_1$ scores for each algorithm-vectorizer combination, using cross-validation with five *k*-folds, are displayed, along with corresponding training scores to determine the extent to which a given model is overfit. [This notebook](prep/Model_General_Testing.ipynb) details this process more verbosely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T17:01:09.082722Z",
     "start_time": "2022-05-26T16:59:42.463382Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidf', TfidfVectorizer()), ('mnb', MultinomialNB())])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_count_pipe = Pipeline(steps=[\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "                          \n",
    "mnb_tfidf_pipe = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])         \n",
    "                          \n",
    "# Fitting simple model(s) to validation sets\n",
    "mnb_count_pipe.fit(X_tr_val, y_tr_val)\n",
    "mnb_tfidf_pipe.fit(X_tr_val, y_tr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T17:04:52.580202Z",
     "start_time": "2022-05-26T17:02:37.132693Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.955\n",
      "Test accuracy:     0.890\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.954\n",
      "Test F1 score:     0.886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.3min finished\n"
     ]
    }
   ],
   "source": [
    "mnb_count_model = ModelForScoring(mnb_count_pipe, 'mnb_cvec', X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T17:07:02.032931Z",
     "start_time": "2022-05-26T17:04:52.677192Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 0.833\n",
      "Test accuracy:     0.777\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 0.818\n",
      "Test F1 score:     0.750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  2.2min finished\n"
     ]
    }
   ],
   "source": [
    "mnb_tfidf_model = ModelForScoring(mnb_tfidf_pipe, 'mnb_tfidf', X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "[This notebook](prep/Model_Tuning.ipynb) details the tuning process following selection more verbosely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:24:28.984162Z",
     "start_time": "2022-05-25T21:24:28.975948Z"
    }
   },
   "outputs": [],
   "source": [
    "#pickle.dump()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/acc_scores_bar.png)\n",
    "\n",
    "---\n",
    "\n",
    "![img](images/f1_scores_bar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Unseen Data\n",
    "\n",
    "<!--- bar graph of dummy classifier, simple model, better models, best model - acc and F1 -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Metrics\n",
    "\n",
    "<!--- image of ROC curves for various algorithms --->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "You can view the code that deploys the Streamlit application [here](app_testing.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:40:28.514542Z",
     "start_time": "2022-05-18T20:40:28.496607Z"
    }
   },
   "source": [
    "## Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use web scraping to **create new features** - number of citations in an article is worth exploring.\n",
    "- **Multilabel classification** - can we determine more distinctly what kind of promotional tone is being used in a given article?\n",
    "    - This may require **upsampling**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations and Further Reading\n",
    "\n",
    "### Internal Links\n",
    "\n",
    "- The [GitHub repository](https://github.com/toastdeini/Wikipedia-article-quality) for this project.\n",
    "- The [raw dataset](https://www.kaggle.com/datasets/urbanbricks/wikipedia-promotional-articles) used for this project, hosted on Kaggle.\n",
    "\n",
    "### Outside Resources & References\n",
    "\n",
    "- etc.\n",
    "- etc."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7cbf54eddb5aed001a886b10091ff8575864d33f1f9e8791abcee4b91a7c7e0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
