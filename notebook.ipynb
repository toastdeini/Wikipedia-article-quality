{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Wikipedia Article Quality With Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/header.jpg)\n",
    "\n",
    "*(photo courtesy of Dmitrij Paskevic, hosted on [Unsplash](https://unsplash.com/photos/YjVa-F9P9kk))*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author\n",
    "\n",
    "> **Luke Dowker** ([GitHub](https://github.com/toastdeini) | [LinkedIn](https://www.linkedin.com/in/luke-dowker/) | [Email](mailto:lhdowker@gmail.com))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "Over the course of its twenty-plus-year existence, Wikipedia's reputation has gradually evolved from that of a [digital \"Wild West\"](https://www.cnn.com/2009/TECH/08/26/wikipedia.editors/index.html), [replete with misinformation](https://usatoday30.usatoday.com/news/opinion/editorials/2005-11-29-wikipedia-edit_x.htm), to that of a [meticulously curated](https://en.wikipedia.org/wiki/Vandalism_on_Wikipedia#Prevention) and (generally) reliable resource for [fact-checking](https://en.wikipedia.org/wiki/Wikipedia_and_fact-checking) & bird's-eye/survey-level research.\n",
    "\n",
    "The site's reliability and ongoing improvement can be attributed, in large part, to the fastidiousness of Wikipedia's volunteer editors, who have been using Bayesian statistics for at least fifteen years now to identify \"[vandalism](https://en.wikipedia.org/wiki/Wikipedia:Vandalism)\" - bad-faith edits \"deliberately intended to obstruct\" the distribution of verifiable, open-source knowledge - with scripts like [ClueBot](https://en.wikipedia.org/wiki/User:ClueBot_NG). The steadily increasing proportion of \"[good articles](https://en.wikipedia.org/wiki/Wikipedia:Good_article_statistics)\" is the direct result of a concerted, altruistic effort by English speakers across the world to create an accessible, democratized encyclopedia.\n",
    "\n",
    "![img](images/pct_good_articles.png)\n",
    "\n",
    "*(This image recreated from a similar Wikipedia graph - code for this is located in the [EDA notebook](prep/Exploratory_Analysis_and_Visualization.ipynb).)*\n",
    "\n",
    "Regrettably, not everyone who fires up their computer (or phone!) to edit Wikipedia has equally noble intentions. Though the site's policy makes clear that Wikipedia is \"[**not** a soapbox or means of promotion](https://en.wikipedia.org/wiki/Wikipedia:What_Wikipedia_is_not#Wikipedia_is_not_a_soapbox_or_means_of_promotion)\" (emphasis mine), upwards of 20,000 articles on the site fail to purport a neutral point of view, and hundreds of these \"[articles with a promotional tone](https://en.wikipedia.org/wiki/Category:Articles_with_a_promotional_tone)\" are identified monthly by editors and everyday visitors.\n",
    "\n",
    "Articles with a slanted perspective present a threat not only to Wikipedia's credibility as a source of knowledge, but also to the average user: without prior knowledge of the subject at hand, how can a reader know if the information they're getting is objective, other than by intuition? This is where machine learning and natural language processing (NLP) enter the picture: a model trained on data that represents the contents of **both \"good\" and \"promotional\" articles** will be able to forecast whether a body of text meets an encyclopedic editorial standard, or if the text is likely to be marked by readers as \"promotional\" and thus not useful.\n",
    "\n",
    "The final model classifies unseen documents with an accuracy rate hovering **just above 90%** using a term importance (TF-IDF) vectorizer and a classifier from the popular `XGBoost` library. Users inputting a passage of text into the [application](https://share.streamlit.io/toastdeini/wikipedia-article-quality/main/app_testing.py) that employs this model can be confident that, nine times out of ten, they will know almost immediately if a given Wikipedia is written from a sufficiently neutral point of view, or if the article is more like a glorified advertisement."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Business Problem\n",
    "\n",
    "First, the good news: Wikipedia is better than it’s ever been. It was frequently criticized in its infancy for the unreliability of its contents, but the site’s volunteer editors have worked tirelessly over the years to track and remove vandalism while demanding a rigorous editorial standard.\n",
    "\n",
    "As a result, the number of articles on Wikipedia that contain “factually accurate and verifiable information […and are] neutral in point of view” has been steadily increasing since the site started labeling and tracking “good articles” in 2006.\n",
    "\n",
    "…That said, while it’s a core principle of the site that anyone can edit Wikipedia, not all edits are done in good faith. Blatant vandalism and spam are ongoing problems, but ones that are easily rectified with existing Wikipedia scripts like ClueBot, which uses naïve Bayes classification to detect “bad” edits.\n",
    "\n",
    "On the other hand, articles written in a “promotional tone” pose a more existential threat to Wikipedia, as the information they purvey is biased. It’s more difficult to parse tone than to identify a simple instance of childish vandalism, especially if you know nothing about a subject.\n",
    "\n",
    "This is where **natural language processing** comes in handy! Using the text of Wikipedia articles that have already been identified as either good or having a promotional tone, we can train a model that’s able to **predict which class an unlabeled article will belong to!**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "> All data used in this project has been uploaded externally by the author [here](https://www.mediafire.com/folder/kqlo7r936ufdp/flatiron-capstone-data) to expedite reproducibility, due to the size of the combined, lemmatized `.csv` file.\n",
    "\n",
    "Data used in this project is freely available for download on [Kaggle](https://www.kaggle.com/datasets/urbanbricks/wikipedia-promotional-articles), courtesy of user `urbanbricks`. \"[Good articles](https://en.wikipedia.org/wiki/Wikipedia:Good_articles)\" - articles which meet a \"core set of editorial standards\" - were stored as strings (with corresponding URLs) in one CSV file, `good.csv`. Articles with a \"[promotional tone](https://en.wikipedia.org/wiki/Category:Articles_with_a_promotional_tone)\" were stored in a separate CSV (`promotional.csv`) that, in addition to `text` and `url` columns, contains one-hot encoded columns that identify a subclass of promotional tone, e.g. `advert` (written like an advertisement) or `coi` (conflict of interest with subject).\n",
    "\n",
    "> Full exploratory data analysis, including all visualizations created for this project, is available in [this notebook](prep/Exploratory_Analysis_and_Visualization.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries, Packages, and Scripts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:20.685542Z",
     "start_time": "2022-06-03T17:44:18.584845Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data comprehension/manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Loading in stored objects\n",
    "import pickle\n",
    "\n",
    "# Visualization\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# Machine learning packages\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "# Natural language processing\n",
    "import nltk\n",
    "\n",
    "# etc.\n",
    "import os\n",
    "import sys\n",
    "module_path = os.path.abspath(os.pardir)\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "    \n",
    "# Custom/helper functions\n",
    "from src.parse_it import *\n",
    "from src.modeling import *\n",
    "from src.EDA import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load in Data\n",
    "\n",
    "Full exploratory data analysis for this project can be found in [a separate notebook](prep/Exploratory_Analysis_and_Visualization.ipynb); this final notebook contains the most notable parts of that analysis, with truncated/imported code whenever possible.\n",
    "\n",
    "Data is stored in two separate `.csv` files; one contains articles marked as \"good,\" while the other contains articles marked as \"promotional,\" with various subclasses of \"promotional.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:30.717874Z",
     "start_time": "2022-06-03T17:44:23.244949Z"
    }
   },
   "outputs": [],
   "source": [
    "df_good = pd.read_csv('../data/good.csv')\n",
    "df_promo = pd.read_csv('../data/promotional.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Data Exploration and Preparation](prep/Exploratory_Analysis_and_Visualization.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, I examine the size of the dataset and the distribution of the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:30.841081Z",
     "start_time": "2022-06-03T17:44:30.813017Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30279 documents in this file/dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nycticebus linglom is a fossil strepsirrhine p...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/%3F%20Nycticebus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Oryzomys pliocaenicus is a fossil rodent from ...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/%3F%20Oryzomys%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>.hack dt hk is a series of single player actio...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/.hack%20%28video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The You Drive Me Crazy Tour was the second con...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/%28You%20Drive%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0 8 4 is the second episode of the first seaso...</td>\n",
       "      <td>https://en.wikipedia.org/wiki/0-8-4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  \\\n",
       "0  Nycticebus linglom is a fossil strepsirrhine p...   \n",
       "1  Oryzomys pliocaenicus is a fossil rodent from ...   \n",
       "2  .hack dt hk is a series of single player actio...   \n",
       "3  The You Drive Me Crazy Tour was the second con...   \n",
       "4  0 8 4 is the second episode of the first seaso...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://en.wikipedia.org/wiki/%3F%20Nycticebus...  \n",
       "1  https://en.wikipedia.org/wiki/%3F%20Oryzomys%2...  \n",
       "2  https://en.wikipedia.org/wiki/.hack%20%28video...  \n",
       "3  https://en.wikipedia.org/wiki/%28You%20Drive%2...  \n",
       "4                https://en.wikipedia.org/wiki/0-8-4  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{df_good.shape[0]} documents in this file/dataset:\") \n",
    "df_good.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:30.980705Z",
     "start_time": "2022-06-03T17:44:30.958900Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23837 documents in this file/dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>advert</th>\n",
       "      <th>coi</th>\n",
       "      <th>fanpov</th>\n",
       "      <th>pr</th>\n",
       "      <th>resume</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Litre no Namida 1, lit. 1 Litre of Tears als...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/1%20Litre%20no%2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1DayLater was free, web based software that wa...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/1DayLater</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1E is a privately owned IT software and servic...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/1E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1Malaysia pronounced One Malaysia in English a...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/1Malaysia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The Jerusalem Biennale, as stated on the Bienn...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>https://en.wikipedia.org/wiki/1st%20Jerusalem%...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  advert  coi  fanpov  pr  \\\n",
       "0  1 Litre no Namida 1, lit. 1 Litre of Tears als...       0    0       1   0   \n",
       "1  1DayLater was free, web based software that wa...       1    1       0   0   \n",
       "2  1E is a privately owned IT software and servic...       1    0       0   0   \n",
       "3  1Malaysia pronounced One Malaysia in English a...       1    0       0   0   \n",
       "4  The Jerusalem Biennale, as stated on the Bienn...       1    0       0   0   \n",
       "\n",
       "   resume                                                url  \n",
       "0       0  https://en.wikipedia.org/wiki/1%20Litre%20no%2...  \n",
       "1       0            https://en.wikipedia.org/wiki/1DayLater  \n",
       "2       0                   https://en.wikipedia.org/wiki/1E  \n",
       "3       0            https://en.wikipedia.org/wiki/1Malaysia  \n",
       "4       0  https://en.wikipedia.org/wiki/1st%20Jerusalem%...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"{df_promo.shape[0]} documents in this file/dataset:\") \n",
    "df_promo.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Curious about the distribution of subclasses in `df_promo` - that is, in what way can its promotional tone *best be described?* - I plotted the value counts of the categorical columns:\n",
    "\n",
    "- **Advertisement-like** / `advert` - The article reads like an advertisement for a company, a product, or an organization, or is otherwise an advertisement \"masquerading\" as a legitimate article.\n",
    "- **Conflict of interest** / `coi` - There appears to be a conflict of interest between the subject of the article and the author of the article, which \"undermines public confidence\" in Wikipedia.\n",
    "- **Fan's point of view** / `fanpov` - The article appears to have been written by a fan or admirer of the subject, rather than from a neutral point of view.\n",
    "- **News article/press release-like** / `pr` - The article reads like a news article, i.e. \"the article may not be promotional or overly-negative, but is still unencyclopedic in tone.\"\n",
    "- **Résumé-like** / `resume` - The article reads like a résumé or CV.\n",
    "\n",
    "---\n",
    "\n",
    "![img](images/promo_dist.png)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imbalance of promotional subclasses in the dataset, along with the overlap in semantic meaning between the subclass descriptions - *are these not all 'promotional' in some form or another?* - shaped my decision to approach this project as a **binary classification problem**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:31.106344Z",
     "start_time": "2022-06-03T17:44:31.085702Z"
    }
   },
   "outputs": [],
   "source": [
    "df_good = df_good[['text']]\n",
    "df_promo = df_promo[['text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All rows in `good.csv` were assigned the label `0`, indicating that the article is *not* promotional, whereas all rows in `promotional.csv` were assigned the label `1`, regardless of their subclass."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:31.214722Z",
     "start_time": "2022-06-03T17:44:31.203751Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nycticebus linglom is a fossil strepsirrhine p...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  Nycticebus linglom is a fossil strepsirrhine p...      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning 'good' articles the label 0, a 'falsy' value,\n",
    "# indicating that the article is NOT promotional\n",
    "\n",
    "df_good['label'] = 0\n",
    "df_good.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:31.337958Z",
     "start_time": "2022-06-03T17:44:31.309550Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Litre no Namida 1, lit. 1 Litre of Tears als...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  label\n",
       "0  1 Litre no Namida 1, lit. 1 Litre of Tears als...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assigning 'promotional' articles the label 1, a 'truthy'\n",
    "# value, indicating that the article IS promotional\n",
    "\n",
    "df_promo['label'] = 1\n",
    "df_promo.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The two dataframe objects were then concatenated to prepare the data for modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:31.462735Z",
     "start_time": "2022-06-03T17:44:31.438989Z"
    }
   },
   "outputs": [],
   "source": [
    "# Concatenate dataframes - reset index of `df_promo`\n",
    "# for numeric consistency\n",
    "\n",
    "# Replace .append with .concat if using newer pandas version\n",
    "\n",
    "df = df_good.append(df_promo,\n",
    "                    ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:31.586924Z",
     "start_time": "2022-06-03T17:44:31.558896Z"
    }
   },
   "outputs": [],
   "source": [
    "# Shuffle dataframe for randomness, etc.\n",
    "\n",
    "df = df.sample(frac=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following some investigation into document word counts, I found that \"good\" articles were about **four times longer** on average than promotional articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:41:33.530775Z",
     "start_time": "2022-06-03T17:41:16.005035Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "compare_mean_counts(df, 'text', 'label', 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/median_word_count.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following cell is one of the most computationally expensive tasks in this whole project - it applies the custom function `parse_doc` (see the [.py file](src/parse_it.py) for further information) to the content of the `text` column for each row in the dataframe, i.e. each document in the corpus. The result is a string of **lemmas**, the approximate morphological roots of each word in the document, stored in a new column called `text_lem`. This helps standardize the text for vectorization and, eventually, modeling.\n",
    "\n",
    "Again, the following two cells are only necessary to run if you're interested in completing reproducing the project, step by step. For convenience, the output is saved as `lemmed_combined.csv`, which will probably save you at least an hour of computing time if loaded in."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:41:33.609760Z",
     "start_time": "2022-06-03T17:41:33.599210Z"
    }
   },
   "outputs": [],
   "source": [
    "# df['text_lem'] = df['text'].apply(parse_doc) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:41:33.703132Z",
     "start_time": "2022-06-03T17:41:33.690648Z"
    }
   },
   "outputs": [],
   "source": [
    "# df.to_csv('lemmed_combined.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods and Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below, the updated `.csv` file is read in - it can be downloaded externally [here](https://www.mediafire.com/folder/kqlo7r936ufdp/flatiron-capstone-data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:44.381144Z",
     "start_time": "2022-06-03T17:44:31.714869Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Read in usable dataframe\n",
    "\n",
    "df = pd.read_csv('../data/lemmed_combined.csv',\n",
    "                 index_col=0)\n",
    "\n",
    "# Reorder columns, keeping only the lemmatized text\n",
    "\n",
    "df = df[['text_lem', 'label']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:44.490431Z",
     "start_time": "2022-06-03T17:44:44.477898Z"
    }
   },
   "outputs": [],
   "source": [
    "X = df['text_lem']\n",
    "y = df['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:44.691837Z",
     "start_time": "2022-06-03T17:44:44.586602Z"
    }
   },
   "outputs": [],
   "source": [
    "# Train-test split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                    random_state=138,\n",
    "                                                    stratify=y)\n",
    "\n",
    "# Secondary train-test split for validation\n",
    "\n",
    "X_tr_val, X_val, y_tr_val, y_val = train_test_split(X_train, y_train,\n",
    "                                                    random_state=138,\n",
    "                                                    stratify=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline Model: `DummyClassifier`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "scikit-learn's `DummyClassifier` was used as a baseline for measuring model performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-29T06:44:11.212824Z",
     "start_time": "2022-05-29T06:44:11.199537Z"
    }
   },
   "outputs": [],
   "source": [
    "dum_pipe = Pipeline(steps=[\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('dum', DummyClassifier(strategy='most_frequent'))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:50:40.134883Z",
     "start_time": "2022-05-25T21:50:17.472622Z"
    }
   },
   "outputs": [],
   "source": [
    "dum_pipe.fit(X_tr_val, y_tr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-25T21:51:06.091372Z",
     "start_time": "2022-05-25T21:50:40.213973Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dum_pipe.score(X_tr_val, y_tr_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [Algorithm Exploration](prep/Model_General_Testing.ipynb)\n",
    "\n",
    "To create some simple models, I train scikit-learn's `MultinomialNB` algorithm (default hyperparameters) on two vectorized instances of the corpus: One using a `CountVectorizer`, a simple bag-of-words approach, and the other using `TfidfVectorizer`, a term importance approach. Accuracy and $F_1$ scores for each algorithm-vectorizer combination, using cross-validation with five *k*-folds, are displayed, along with corresponding training scores to determine the extent to which a given model is overfit. [This notebook](prep/Model_General_Testing.ipynb) details this process more verbosely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T17:01:09.082722Z",
     "start_time": "2022-05-26T16:59:42.463382Z"
    }
   },
   "outputs": [],
   "source": [
    "mnb_count_pipe = Pipeline(steps=[\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])\n",
    "                          \n",
    "mnb_tfidf_pipe = Pipeline(steps=[\n",
    "    ('tfidf', TfidfVectorizer()),\n",
    "    ('mnb', MultinomialNB())\n",
    "])         \n",
    "                          \n",
    "# Fitting simple model(s) to validation sets\n",
    "mnb_count_pipe.fit(X_tr_val, y_tr_val)\n",
    "mnb_tfidf_pipe.fit(X_tr_val, y_tr_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T17:04:52.580202Z",
     "start_time": "2022-05-26T17:02:37.132693Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mnb_count_model = ModelForScoring(mnb_count_pipe, 'mnb_cvec', X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-26T17:07:02.032931Z",
     "start_time": "2022-05-26T17:04:52.677192Z"
    }
   },
   "outputs": [],
   "source": [
    "mnb_tfidf_model = ModelForScoring(mnb_tfidf_pipe, 'mnb_tfidf', X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Selection\n",
    "\n",
    "[This notebook](prep/Model_Tuning.ipynb) details the tuning process following selection more verbosely. The gradient boosting algorithm `XGBoost` performed best on validation data, with an accuracy score of **0.945.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:44:45.157547Z",
     "start_time": "2022-06-03T17:44:44.833131Z"
    }
   },
   "outputs": [],
   "source": [
    "with open('models/xgb_model.sav', 'rb') as f:\n",
    "    final_model = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T17:56:07.512271Z",
     "start_time": "2022-06-03T17:45:42.692703Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CV Results\n",
      "================================\n",
      "Accuracy\n",
      "--------------------------------\n",
      "Training accuracy: 1.000\n",
      "Test accuracy:     0.945\n",
      "F-1 Score\n",
      "--------------------------------\n",
      "Training F1 score: 1.000\n",
      "Test F1 score:     0.944\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   5 out of   5 | elapsed:  6.3min finished\n"
     ]
    }
   ],
   "source": [
    "final_model.fit(X_tr_val, y_tr_val)\n",
    "\n",
    "model = ModelForScoring(final_model, 'xgb_tfidf', X_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/acc_scores_bar.png)\n",
    "\n",
    "---\n",
    "\n",
    "![img](images/f1_scores_bar.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance on Unseen Data\n",
    "\n",
    "<!--- bar graph of dummy classifier, simple model, better models, best model - acc and F1 -->"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T18:06:45.435933Z",
     "start_time": "2022-06-03T18:00:47.590527Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9559464853278143"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_model.fit(X_train, y_train)\n",
    "\n",
    "final_model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-03T18:09:33.001830Z",
     "start_time": "2022-06-03T18:09:15.031048Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.96      0.96      7570\n",
      "           1       0.95      0.94      0.95      5959\n",
      "\n",
      "    accuracy                           0.96     13529\n",
      "   macro avg       0.96      0.95      0.96     13529\n",
      "weighted avg       0.96      0.96      0.96     13529\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, final_model.predict(X_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After allowing the model to see a larger training set, final accuracy and macro $F_1$ scores on unseen data were both **`0.96`**. Considering that the baseline performance was only `0.55` / 55% accuracy, I'm satisfied with this result, to say the least."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deployment\n",
    "\n",
    "You can view the code that deploys the Streamlit application [here](app_testing.py)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](images/wiki_app.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-18T20:40:28.514542Z",
     "start_time": "2022-05-18T20:40:28.496607Z"
    }
   },
   "source": [
    "## Conclusions\n",
    "\n",
    "1. **Integrate the model/application into existing Wikipedia UI:** This could immediately assist site visitors who are curious about the verifiability or quality of an article they might be reading.\n",
    "\n",
    "2. **Auto-classify articles for expedited review:** Create *preliminary classifications* for unlabeled articles, which can later be reviewed by Wikipedia contributors and editors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps\n",
    "\n",
    "![img](images/citation.png)\n",
    "\n",
    "*(Image courtesy of [Wikimedia Commons](https://upload.wikimedia.org/wikipedia/commons/1/18/%22Citation_needed%22.jpg))*\n",
    "\n",
    "- **Collaborate with administrators of [Fandom](https://www.fandom.com/explore) wikis to gather new, robust training data:** Articles containing in-depth information on a wider variety of subjects - especially niche ones - than Wikipedia offers might help the model's performance on unseen data.\n",
    "- **Engineer additional features:** The number of citations in an article, for instance, might be a relevant predictor of the article's objective quality. The bar charts displaying the disparate median word count between \"good\" and \"promotional\" articles also present a strong case for further examining word count as a predictive feature.\n",
    "- **Explore new vectorization and modeling techniques:** Methods like *word embedding* and incorporating neural network algorithms might improve model performance, especially on less \"clean\" data than Wikipedia provides.\n",
    "- **Refine application to accept URLs as input:** Including options to input **either** raw text or a URL into the model for classification would further streamline the user experience."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Citations and Further Reading\n",
    "\n",
    "### Internal Links\n",
    "\n",
    "- The [GitHub repository](https://github.com/toastdeini/Wikipedia-article-quality) for this project.\n",
    "- The [raw dataset](https://www.kaggle.com/datasets/urbanbricks/wikipedia-promotional-articles) used for this project, hosted on Kaggle.\n",
    "\n",
    "### Outside Resources & References\n",
    "\n",
    "- etc.\n",
    "- etc."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "a7cbf54eddb5aed001a886b10091ff8575864d33f1f9e8791abcee4b91a7c7e0"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
